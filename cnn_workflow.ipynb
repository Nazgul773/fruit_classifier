{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-26T16:21:37.663155Z",
     "start_time": "2024-05-26T16:21:35.737367Z"
    }
   },
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "\n",
    "from models import FruitVeggieClassifier0Acc, FruitVeggieClassifier55Acc"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:21:37.679160Z",
     "start_time": "2024-05-26T16:21:37.664153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hyperparameter\n",
    "num_classes = 36\n",
    "num_epochs = 20\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "1d376e7da9c6dde8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Augmentation and Normalization",
   "id": "29040a8f67a28fee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:21:37.694093Z",
     "start_time": "2024-05-26T16:21:37.679160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the image transformation with data augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(128),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406, 0.5], std=[0.229, 0.224, 0.225, 0.5])\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize(144),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406, 0.5], std=[0.229, 0.224, 0.225, 0.5])\n",
    "])"
   ],
   "id": "c79a65078181d1b7",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:21:37.709601Z",
     "start_time": "2024-05-26T16:21:37.695093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the data loaders\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert('RGBA')"
   ],
   "id": "68fcfbe4d395b9df",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:21:37.725600Z",
     "start_time": "2024-05-26T16:21:37.710601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ImageFolderWithPaths(ImageFolder):\n",
    "    \"\"\"Custom dataset that includes image file paths. Extends torchvision.datasets.ImageFolder\"\"\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # This is what ImageFolder normally returns \n",
    "        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        # The image file path\n",
    "        path = self.imgs[index][0]\n",
    "        # Make a new tuple that includes original and the path\n",
    "        tuple_with_path = (original_tuple + (path,))\n",
    "        return tuple_with_path"
   ],
   "id": "21f702e5398cce50",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:21:37.741600Z",
     "start_time": "2024-05-26T16:21:37.726599Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = 'data'\n",
    "train_data = ImageFolder(root=os.path.join(data_dir, 'train'), transform=train_transform, loader=pil_loader)\n",
    "val_data = ImageFolder(root=os.path.join(data_dir, 'val'), transform=val_test_transform, loader=pil_loader)\n",
    "benchmark_data = ImageFolderWithPaths(root=os.path.join(data_dir, 'test'), transform=val_test_transform,\n",
    "                                      loader=pil_loader)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "benchmark_loader = DataLoader(benchmark_data, batch_size=16, shuffle=False)  #, collate_fn=my_collate)"
   ],
   "id": "c58b8af09d1a4f14",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Architecture",
   "id": "8fd11be9aba65ea3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:21:37.757603Z",
     "start_time": "2024-05-26T16:21:37.742601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Option to build the model from scratch or load a saved model\n",
    "def build_or_load_model(load_model, model):\n",
    "    path = model.model_path\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "    start_epoch = 0\n",
    "\n",
    "    if load_model and os.path.exists(path):\n",
    "        checkpoint = torch.load(path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        print(\"Model loaded successfully.\")\n",
    "    else:\n",
    "        print(\"Model built from scratch.\")\n",
    "\n",
    "    return model, optimizer, scheduler, start_epoch"
   ],
   "id": "303587d5357d7b93",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:21:41.486757Z",
     "start_time": "2024-05-26T16:21:41.469757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_validate(model, optimizer, scheduler, start_epoch, num_epochs=num_epochs, patience=5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    epochs_without_improvement = 0\n",
    "    save_path = model.model_path\n",
    "    \n",
    "    for epoch in range(start_epoch, start_epoch + num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # zero the parameter gradients\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(images) \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward() \n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch + 1}/{start_epoch + num_epochs}], Train Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "        current_lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "        print(f'Current learning rate: {current_lr:.6f}')\n",
    "\n",
    "        # Check for early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_epoch = epoch\n",
    "            epochs_without_improvement = 0\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'loss': running_loss,\n",
    "            }, save_path)\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(\n",
    "                    f'Early stopping at epoch {epoch + 1}. Best validation loss: {best_val_loss:.4f} at epoch {best_epoch + 1}.')\n",
    "                break"
   ],
   "id": "725be25848e20a49",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:21:42.856657Z",
     "start_time": "2024-05-26T16:21:42.728657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_model = True  # Change this to True if you want to load a pre-trained model\n",
    "init_model = FruitVeggieClassifier55Acc(num_classes=num_classes).to(device)\n",
    "net, optimizer, scheduler, start_epoch = build_or_load_model(load_model=load_model, model=init_model)  "
   ],
   "id": "10aa5ded12d1e791",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:28:11.976467Z",
     "start_time": "2024-05-26T16:21:43.787659Z"
    }
   },
   "cell_type": "code",
   "source": "train_and_validate(net, optimizer, scheduler, start_epoch, start_epoch + num_epochs)",
   "id": "2f00055a2c58a833",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [190/398], Train Loss: 1.2179\n",
      "Validation Loss: 1.4403, Accuracy: 64.80%\n",
      "Current learning rate: 0.000001\n",
      "Epoch [191/398], Train Loss: 1.1730\n",
      "Validation Loss: 1.4404, Accuracy: 64.80%\n",
      "Current learning rate: 0.000001\n",
      "Epoch [192/398], Train Loss: 1.2083\n",
      "Validation Loss: 1.4405, Accuracy: 64.80%\n",
      "Current learning rate: 0.000001\n",
      "Epoch [193/398], Train Loss: 1.2022\n",
      "Validation Loss: 1.4408, Accuracy: 64.80%\n",
      "Current learning rate: 0.000000\n",
      "Epoch [194/398], Train Loss: 1.2284\n",
      "Validation Loss: 1.4409, Accuracy: 64.80%\n",
      "Current learning rate: 0.000000\n",
      "Epoch [195/398], Train Loss: 1.2037\n",
      "Validation Loss: 1.4412, Accuracy: 64.80%\n",
      "Current learning rate: 0.000000\n",
      "Early stopping at epoch 195. Best validation loss: 1.4403 at epoch 190.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing the Model",
   "id": "2f743f516c8bfe99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:28:11.991656Z",
     "start_time": "2024-05-26T16:28:11.977472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    data = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels, paths in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            # Save the image paths and class labels\n",
    "            for path, label in zip(paths, predicted):\n",
    "                class_name = benchmark_data.classes[label]  # Get the class name\n",
    "                data.append([Path(path).stem, class_name])\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['id', 'ClassLabel'])\n",
    "    model_path = model.model_path\n",
    "    model_name = os.path.splitext(os.path.basename(model_path))[0]\n",
    "    output_dir = os.path.join(\"results\", os.path.dirname(model_path), model_name)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    output_file = os.path.join(output_dir, f\"result_{current_time}.csv\")\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"CSV file has been created: {output_file}\")"
   ],
   "id": "26ffc2ae0cf83e41",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T16:28:24.321638Z",
     "start_time": "2024-05-26T16:28:11.992655Z"
    }
   },
   "cell_type": "code",
   "source": "evaluate(net, benchmark_loader)",
   "id": "e5eec472ad8807ab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 57.30%\n",
      "CSV file has been created: results\\models\\model_1\\result_2024-05-26_18-28-24.csv\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## References\n",
    "- https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html\n",
    "- https://pyimagesearch.com/2021/07/19/pytorch-training-your-first-convolutional-neural-network-cnn/"
   ],
   "id": "869bef9d4fcec19f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "59d9e180c6aafa96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cc73be4496066063"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
